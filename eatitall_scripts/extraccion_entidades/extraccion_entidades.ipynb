{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/eatitall_scripts')\n",
    "sys.path.insert(1, '/home/root/pctobs/lib/python3.8/site-packages')\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "def encontrar_alimentos(df,vocab_alimentos):\n",
    "    todos_los_alimentos = [item for sublist in vocab_alimentos.values() for item in sublist]\n",
    "    for k in range(0,len(df)):\n",
    "        texto_entrada=df['observaciones'][k]\n",
    "        texto = texto_entrada.lower()\n",
    "        palabras = re.split(r'[ ,.;]+', texto)\n",
    "        alimentos_encontrados = []\n",
    "        i = 0\n",
    "        while i < len(palabras):\n",
    "            max_longitud = 0\n",
    "            alimento_a_agregar = ''\n",
    "            for alimento in todos_los_alimentos:\n",
    "                alimento_partes = re.split(r'[ ,.;]+',alimento.lower())\n",
    "                longitud = len(alimento_partes)\n",
    "                # Comprobar si la secuencia de palabras coincide con algún alimento\n",
    "                if palabras[i:i+longitud] == alimento_partes and longitud > max_longitud:\n",
    "                    # Guardar el alimento más largo que coincide\n",
    "                    alimento_a_agregar = ' '.join(palabras[i:i+longitud])\n",
    "                    max_longitud = longitud\n",
    "            if max_longitud > 0:\n",
    "                alimentos_encontrados.append(alimento_a_agregar)\n",
    "                i += max_longitud  # Ajustar el índice según la longitud del alimento encontrado más largo\n",
    "            else:\n",
    "                i += 1\n",
    "        alimentos_string = ', '.join(alimentos_encontrados)\n",
    "        df.loc[k,'alimentos_encontrados']=alimentos_string\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Insertando rutas al sys.path\n",
    "sys.path.insert(1, '/home/eatitall_scripts')\n",
    "sys.path.insert(1, '/home/root/pctobs/lib/python3.8/site-packages')\n",
    "\n",
    "# Función para calcular la distancia de Levenshtein\n",
    "def distancia_levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return distancia_levenshtein(s2, s1)\n",
    "\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    matriz_previa = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        matriz_actual = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            inserciones = matriz_previa[j + 1] + 1\n",
    "            eliminaciones = matriz_actual[j] + 1\n",
    "            sustituciones = matriz_previa[j] + (c1 != c2)\n",
    "            matriz_actual.append(min(inserciones, eliminaciones, sustituciones))\n",
    "        matriz_previa = matriz_actual\n",
    "    \n",
    "    return matriz_previa[-1]\n",
    "\n",
    "# Función mejorada para encontrar alimentos considerando la distancia de Levenshtein\n",
    "def encontrar_alimentos(df, vocab_alimentos, umbral_levenshtein=2):\n",
    "    todos_los_alimentos = [item for sublist in vocab_alimentos.values() for item in sublist]\n",
    "    for k in range(len(df)):\n",
    "        texto_entrada = df['observaciones'][k].lower()\n",
    "        palabras = re.split(r'[ ,.;]+', texto_entrada)\n",
    "        alimentos_encontrados = []\n",
    "\n",
    "        i = 0\n",
    "        while i < len(palabras):\n",
    "            max_longitud = 0\n",
    "            alimento_a_agregar = ''\n",
    "            for alimento in todos_los_alimentos:\n",
    "                alimento_partes = re.split(r'[ ,.;]+', alimento.lower())\n",
    "                longitud = len(alimento_partes)\n",
    "                secuencia_palabras = ' '.join(palabras[i:i+longitud])\n",
    "                # Calcular la distancia de Levenshtein para cada parte del alimento\n",
    "                distancia = sum(distancia_levenshtein(p, ap) for p, ap in zip(palabras[i:i+longitud], alimento_partes)) / longitud\n",
    "                # Verificar si la distancia está dentro del umbral y es la coincidencia más larga\n",
    "                if distancia <= umbral_levenshtein and longitud > max_longitud:\n",
    "                    alimento_a_agregar = secuencia_palabras\n",
    "                    max_longitud = longitud\n",
    "            if max_longitud > 0:\n",
    "                alimentos_encontrados.append(alimento_a_agregar)\n",
    "                i += max_longitud\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "        alimentos_string = ', '.join(alimentos_encontrados)\n",
    "        df.loc[k, 'alimentos_encontrados'] = alimentos_string\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distancia_levenshtein(\"hola que tal\",\"hola tal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esto es un texto con acentos: a, e, i, o, u, n.\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def eliminar_acentos(texto):\n",
    "    \"\"\"\n",
    "    Elimina los acentos del texto proporcionado.\n",
    "    :param texto: cadena de texto a la que se le quieren eliminar los acentos.\n",
    "    :return: texto sin acentos.\n",
    "    \"\"\"\n",
    "    texto_sin_acentos = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    return texto_sin_acentos\n",
    "\n",
    "# Ejemplo de uso:\n",
    "texto_con_acentos = \"Esto es un texto con ácentos: á, é, í, ó, ú, ñ.\"\n",
    "texto_sin_acentos = eliminar_acentos(texto_con_acentos)\n",
    "print(texto_sin_acentos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nerc_diccionario(df,diccionario,tipo_entidad):\n",
    "    if tipo_entidad==\"alimentos\":\n",
    "        todos_los_elementos = [item for sublist in diccionario.values() for item in sublist]\n",
    "    if tipo_entidad==\"farmacos\" or tipo_entidad==\"sintomas\" or tipo_entidad==\"pruebas clinicas\":\n",
    "        todos_los_elementos = [elemento['nombre'] for sublist in diccionario.values() for elemento in sublist]\n",
    "    for k in range(0,len(df)):\n",
    "        texto_entrada=df['observaciones'][k]\n",
    "        texto = texto_entrada.lower()\n",
    "        texto_entrada=unicodedata.normalize('NFKD', texto_entrada).encode('ASCII', 'ignore').decode('ASCII') #Eliminar acentos\n",
    "        palabras = re.split(r'[ ,.;]+', texto)\n",
    "        elementos_encontrados = []\n",
    "        i = 0\n",
    "        while i < len(palabras):\n",
    "            max_longitud = 0\n",
    "            elemento_a_agregar = ''\n",
    "            for elemento in todos_los_elementos:\n",
    "                elemento_partes = re.split(r'[ ,.;]+',elemento.lower())\n",
    "                longitud = len(elemento_partes)\n",
    "                # Comprobar si la secuencia de palabras coincide con algún alimento\n",
    "                if palabras[i:i+longitud] == elemento_partes and longitud > max_longitud:\n",
    "                    # Guardar el alimento más largo que coincide\n",
    "                    elemento_a_agregar = ' '.join(palabras[i:i+longitud])\n",
    "                    max_longitud = longitud\n",
    "            if max_longitud > 0:\n",
    "                elementos_encontrados.append(elemento_a_agregar)\n",
    "                i += max_longitud  # Ajustar el índice según la longitud del alimento encontrado más largo\n",
    "            else:\n",
    "                i += 1\n",
    "        elementos_string = ', '.join(elementos_encontrados)\n",
    "        nombre_columna='NERC '+tipo_entidad\n",
    "        df.loc[k,nombre_columna]=elementos_string\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_alimentos_path='./../archivos/vocab_alimentos.json'\n",
    "vocab_farmacos_path='./../archivos/vocab_farmacos_y_productos_quimicos.json'\n",
    "vocab_sintomas_path='./../archivos/vocab_sintomas.json'\n",
    "vocab_pruebas_clinicas_path='./../archivos/vocab_pruebas_clinicas.json'\n",
    "# Cargamos el VOCABULARIO DE LOS ALIMENTOS\n",
    "with open(vocab_alimentos_path, 'r') as archivo:\n",
    "    vocab_alimentos = json.load(archivo)\n",
    "with open(vocab_farmacos_path, 'r') as archivo:\n",
    "    vocab_farmacos = json.load(archivo)\n",
    "with open(vocab_sintomas_path, 'r') as archivo:\n",
    "    vocab_sintomas = json.load(archivo)\n",
    "with open(vocab_pruebas_clinicas_path, 'r') as archivo:\n",
    "    vocab_pruebas_clinicas = json.load(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hemoglobina A1c',\n",
       " 'Glucosa en ayunas',\n",
       " 'Prueba de tolerancia a la glucosa oral (PTGO)',\n",
       " 'Test de cetonas en sangre',\n",
       " 'Test de cetonas en orina',\n",
       " 'Examen de microalbuminuria',\n",
       " 'Perfil de lípidos',\n",
       " 'Presión arterial',\n",
       " 'Examen de fondo de ojo',\n",
       " 'Prueba de función renal',\n",
       " 'Monitoreo continuo de glucosa (MCG)',\n",
       " 'Prueba de pie diabético',\n",
       " 'Electrocardiograma (ECG)',\n",
       " 'Velocidad de sedimentación globular (VSG)',\n",
       " 'Prueba de tiroides',\n",
       " 'Hemograma completo',\n",
       " 'Prueba de vitamina B12',\n",
       " 'Prueba de vitamina D',\n",
       " 'Prueba de función hepática']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "todos_los_elementos = [elemento['nombre'] for sublist in vocab_pruebas_clinicas.values() for elemento in sublist]\n",
    "todos_los_elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
